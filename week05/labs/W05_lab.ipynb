{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "028e1b8c",
   "metadata": {},
   "source": [
    "# Week 5 Lab\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "For each task, write in the provided cell.\n",
    "\n",
    "\n",
    "## Due date\n",
    "Labs are due each week on Wednesday at 10pm (**Oct 12, 10pm**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd7036b",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "This assignment goes through some familiar code, using a new set of texts: a folder collecting all the Presidential Inaugaral Addresses by U.S. presidents, from George Washington in 1789 to Joe Biden in 2021 (as they are collected [here](https://archive.org/details/Inaugural-Address-Corpus-1789-2009), supplemented from recent ones [here](https://www.presidency.ucsb.edu/documents/presidential-documents-archive-guidebook/inaugural-addresses)).✼\n",
    "\n",
    "## Tasks 1 and 2: Modify and Comment the Code\n",
    "\n",
    "### Task 1\n",
    "\n",
    "Below is the code from lecture. It calculates the overal and standardized type-token ratios for a set of files in a folder named `sot4chaps`, outputting its results into two CSV spreadsheet files. \n",
    "\n",
    "However, the folder containing the presidential speeches whose TTR we want to calculate is named `speeches`, not `sot4chaps`. Find the line of code that specifies which folder to look to calculate TTRs and modify it so that Python looks in the `speeches` folder. (Note: if you don't modify this code correctly, the below code will generate two empty CSV files.)\n",
    "\n",
    "### Task 2\n",
    "\n",
    "For **every single line of code** in the cell below, **add a comment (using `#`) explaining what that line of code does**. Some lines of code appear twice in identical or near-identical form; comment them all, cutting and pasting your explanations if necessary. Comments are not necessary for blank lines with no code in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9524d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter code is provided below.\n",
    "# Modify it so that Python looks in the correct folder for texts to analyze\n",
    "# Then add a comment to EVERY SINGLE LINE OF CODE to explain what it does\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "folder_path = \"sot4chaps/\"\n",
    "\n",
    "sample_size = 0\n",
    "\n",
    "file = open(\"ttr-overall.csv\", mode=\"w\", encoding=\"utf-8\")\n",
    "\n",
    "file.write('\"Text\",\"Types\",\"Tokens\",\"TTR\"\\n')\n",
    "\n",
    "for file_path in sorted(Path(folder_path).glob('*.txt')):\n",
    "    \n",
    "    text = open(file_path, encoding='utf-8').read()\n",
    "    text = re.sub(\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    text_words = text.split()\n",
    "    tokens = len(text_words)\n",
    "    \n",
    "    if sample_size == 0 or tokens < sample_size:\n",
    "        sample_size = tokens\n",
    "    \n",
    "    unique_words = []\n",
    "    \n",
    "    for word in text_words:\n",
    "        word = word.lower()\n",
    "        if word not in unique_words:\n",
    "            unique_words.append(word)\n",
    "            \n",
    "    types = len(unique_words)\n",
    "    \n",
    "    ttr = (types / tokens) * 100\n",
    "    \n",
    "    file.write(f'\"{file_path.stem}\",{types},{tokens},{ttr}\\n')\n",
    "\n",
    "file.close()\n",
    "\n",
    "\n",
    "\n",
    "file = open(\"ttr-standardized.csv\", mode=\"w\", encoding=\"utf-8\")\n",
    "\n",
    "file.write('\"Text\",\"Types\",\"Tokens\",\"TTR\"\\n')\n",
    "\n",
    "for file_path in sorted(Path(folder_path).glob('*.txt')):\n",
    "    text = open(file_path, encoding='utf-8').read()\n",
    "    text = re.sub(\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    text_words = text.split()\n",
    "    text_words_standardized = text_words[:sample_size]\n",
    "    tokens_standardized = len(text_words_standardized)\n",
    "\n",
    "    unique_words_standardized = []\n",
    "    \n",
    "    for word in text_words_standardized:\n",
    "        word = word.lower()\n",
    "        if word not in unique_words_standardized:\n",
    "            unique_words_standardized.append(word)\n",
    "            \n",
    "    types_standardized = len(unique_words_standardized)\n",
    "    \n",
    "    ttr_standardized = (types_standardized / tokens_standardized) * 100\n",
    "    \n",
    "    file.write(f'\"{file_path.stem}\",{types_standardized},{tokens_standardized},{ttr_standardized}\\n')\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e813d016",
   "metadata": {},
   "source": [
    "## Task 3: Make Some Predictions\n",
    "\n",
    "Before you look at the CSV files that the code generates, make some predictions about what you think you might see. Do you expect TTRs of presidential addresses to change over time? Are there particular US presidents you'd expect to have a higher or lower TTR? Do you think that Republican or Democratic presidents will tend to have higher or lower TTRs? Write 1-2 sentences in the Markdown cell below with guesses and predictions?\n",
    "\n",
    "(Note: If you are immune from US cultural imperialism and don't know anything about the history of our neighbour to the south, that is absolutely fine, and you can base your predictions on something other than your intimate knowledge of US history...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48848d2d",
   "metadata": {},
   "source": [
    "(Replace this text and enter your answers here)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5db2b11",
   "metadata": {},
   "source": [
    "## Task 4: Interpret the Results (Sorted by Year)\n",
    "\n",
    "Open the `ttr-standardized.csv` file that is created when the code above is run, where the results are sorted by year. In the cell below, reflect on how these results compare with your predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7599f0d7",
   "metadata": {},
   "source": [
    "(Replace this text and enter your answers here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c806393",
   "metadata": {},
   "source": [
    "## Task 5: Interpret the Results (Sorted by TTR)\n",
    "\n",
    "The code cell below uses a package called `pandas` — which we will be meeting after the midterm — to generate a pretty table that sorts all the presidential speeches by their TTRs, from lowest to highest.\n",
    "\n",
    "(Note that you are not expected to know anything about `pandas` for the midterm itself.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed4fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    # imports the pandas package\n",
    "presidential_speeches = pd.read_csv('ttr-standardized.csv')    # loads the \"ttr-standardized.csv\" file you created above into a pandas \"dataframe\" object\n",
    "presidential_speeches.sort_values(by='TTR')   # sorts the rows from your CSV by TTR from smallest to largest, then displays this as a pretty table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1113da97",
   "metadata": {},
   "source": [
    "Without worrying for now about how `pandas` works (we'll dig into that after the midterm), use the sorted table above to reflect on the TTR experiment we have just conducted.\n",
    "\n",
    "In the Markdown cell below, reflect on whether the sorted results help you to notice any trends in the data. What further insights does the sorted table provide into your predictions, or into the texts themselves?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816e4742",
   "metadata": {},
   "source": [
    "(Replace this text and enter your answers here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60265f34",
   "metadata": {},
   "source": [
    "✼ Pedantic footnote: in fact, this corpus does not include Washington's 1793 address, since it is only 140 words long and using it as the shortest text obscured the TTR trends that were visible with a larger sample. The file with this address is included in the week's homework folder, in a subfolder named `excluded_speeches`, if you want to explore adding it back in. You can also discuss in tutorial whether this was an appropriate way to handle this outlier, and what other options might have been."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48eca11",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9389be",
   "metadata": {},
   "source": [
    "### Optional: Questions about this week's material\n",
    "\n",
    "In the Markdown cell below, please feel free ask any question(s) you have about this week’s lecture material and/or the material in this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c5965d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09032295",
   "metadata": {},
   "source": [
    "## Marking Rubric\n",
    "\n",
    "Two points are awarded for labs: one point for submitting the completed lab on time, and one point for making at honest effort at completing it.\n",
    "\n",
    "\n",
    "## How to Submit\n",
    "1. Download this notebook to your local computer and save it as `W05_lab.ipynb`.\n",
    "\n",
    "2. Log in here: https://markus-ds.teach.cs.toronto.edu\n",
    "\n",
    "3. Submit your homework to `lab5: Lab 5`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
