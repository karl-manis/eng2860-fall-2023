{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bce3b09",
   "metadata": {},
   "source": [
    "\n",
    "# Week 3: Power, Carrying Out a TTR Experiment, and Further Adventures in Python\n",
    "\n",
    "\n",
    "## Part One: Calculating TTRs with web tools\n",
    "\n",
    "AH will next provide of an overview of how to carry out a TTR experiment using web resources and web tools.\n",
    "\n",
    "* finding texts\n",
    "* saving them as text files\n",
    "* cleaning them\n",
    "* calculating TTRs for total texts\n",
    "* calculating standardized TTRs\n",
    "* gathering data in a table\n",
    "\n",
    "\n",
    "## Part Two: \"The Power Chapter\"\n",
    "\n",
    "AH will deliver a brief lecture on this week's reading, D'Ignazio and Klein's \"The Power Chapter\" from *Data Feminism*.\n",
    "\n",
    "The above will also introduce our first \"dataset\": **Project Gutenberg**, which we will discuss in the terms introduced by D'Iganazio and Klein.\n",
    "\n",
    "## Part Three: Indexing and Slicing Strings, String Methods, Tokenizing, Lists, and Loading Files into Python\n",
    "\n",
    "In this section of the lecture, included below, we explore some new methods (pun) and a new data type in Python.\n",
    "\n",
    "This week's lecture draws on Melanie Walsh's chapters on [string methods](https://melaniewalsh.github.io/Intro-Cultural-Analytics/02-Python/06-String-Methods.html), [lists and loops](https://melaniewalsh.github.io/Intro-Cultural-Analytics/02-Python/09-Lists-Loops-Part1.html), and [files and character encoding](https://melaniewalsh.github.io/Intro-Cultural-Analytics/02-Python/07-Files-Character-Encoding.html)\n",
    "\n",
    "## Lab and Homework\n",
    "\n",
    "As always, your weekly lab will be released shortly after lecture on Tuesday, and is due Wednesday at 10pm. Your weekly homework will be released on Thursday after tutorial and is due the following Monday at 10pm.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1546b995",
   "metadata": {},
   "source": [
    "# 3: A Bit of Review\n",
    "\n",
    "Let's start with a few hopefully fun exercises to remind us of some what we learned last time... (And teach us one new thing!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4511430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do you explain these potentially surprising reults?\n",
    "\n",
    "print(3 + 3)\n",
    "print(\"3\" + \"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afa6d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Adam\"\n",
    "print(name * 3)\n",
    "print(name * 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982d2b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True\" + \"False\")\n",
    "print(True + False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6530bbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "True * 3.14159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5efcb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "True / False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320333c3",
   "metadata": {},
   "source": [
    "# Our Coding Task Today\n",
    "\n",
    "Today we're going to learn how to do a hugely important part of our Type/Token Ratio experiment: \n",
    "* Load a text\n",
    "* Break that text into words (**\"tokenize\"** it)\n",
    "* Count the number of words (or \"tokens\") in the text\n",
    "\n",
    "Let's start by doing this task manually. \n",
    "\n",
    "Our sample text will be the opening sentence of Jane Austen's *Pride and Prejudice*:\n",
    "\n",
    "> It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\n",
    "\n",
    "How many words are in this text? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6108a7db",
   "metadata": {},
   "source": [
    "# 3a: Indexing and Slicing strings\n",
    "\n",
    "Let's all get our knives out and slice some strings!\n",
    "\n",
    "![Knife slicing string](knife-string.jpg)\n",
    "\n",
    "A string, as we know, is some text strung together. \n",
    "\n",
    "Let's do the English Lit equivalent of `\"Hello world!\"` and load that first line of *Prejudice* into a string variable called `text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739ec358",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c0b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd03e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fad998",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c63d127",
   "metadata": {},
   "source": [
    "Now let's say we didn't want to read that *whole* opening line (I mean, it's sort of long for modern tastes!), and wanted to chop it up a little bit, say just those famous first six words. Sure, we could *retype them* and put them into a new variable, but that would be a lot of work. I mean, they're already **there** — so how to we access only them?\n",
    "\n",
    "Thankfully, Python has some handy tools for \"indexing\" and \"slicing\" strings. These are both achieved by putting **square brackets** `[ ]` directly after the variable name (or the directly inputted text) that you want to \"slice up.\" \n",
    "\n",
    "## Indexing\n",
    "\n",
    "Let's start with the below. It will display \"unit number one\" from the `text` variable. What do you expect to see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1260e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59e4094",
   "metadata": {},
   "source": [
    "I don't know about you, but that's totally not what I was expecting to get back. \n",
    "* What did *you* expect to see?\n",
    "* How do you explain what we see here? \n",
    "\n",
    "Can we figure it out if we enter a few more?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df76bb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6830bb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddccdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc86bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3710c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053a7041",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a677fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5937e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0effffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f008b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93f7456",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[12]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a283e6f4",
   "metadata": {},
   "source": [
    "What have we learned about how indexing works on strings?\n",
    "* Strings are broken up or \"indexed\" by *character*, not by word. So we have learned that if you just want to pull a single character out of a string — which is called **indexing** a string — the syntax is `string[character_number]`.\n",
    "* **AND PYTHON DOESN'T START COUNTING AT 1, IT STARTS COUNTING AT ZERO!!!!!!!!!!!!!!**\n",
    "\n",
    "![hands start counting at zero](start_at_zero.jpg)\n",
    "\n",
    "The above is another one of those unintuitive things for which there is a perfectly good explanation. **Which David or Mary will offer us!**\n",
    "\n",
    "![misleading list](zero_smartest.jpg)\n",
    "\n",
    "Just so we don't forget this, I'm going to put it in big type:\n",
    "# >>>Python doesn't start counting at 1; it starts counting at 0<<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ce44b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf85aeb9",
   "metadata": {},
   "source": [
    "## Slicing\n",
    "\n",
    "If you want to pull multiple characters out of a string, that's called **slicing**, and the syntax is as follows: \n",
    "\n",
    "> `string[start:stop:step]`, where `start`, `stop`, and `step` are \"index positions\" in the string you want to slice. \n",
    "\n",
    "Again be careful not to use different types of brackets, different kinds of colons, or add any spaces. What kind of reader is the Python Interpreter, again? Right: \"**extraordinarily dutiful but uncompromisingly literal.**\"\n",
    "\n",
    "Now, we don't have to include all three instructions — `start`, `stop`, and `step` — so let's start with just two, `start` and `stop`.\n",
    "\n",
    "Okay, let's try to slice that string so that we only get the first six words, \"It is a truth universally acknowledged.\"\n",
    "\n",
    "But let's start with with just the first FOUR words, which we know go up to `text[12]`. So maybe..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b7fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[0:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5fdf63",
   "metadata": {},
   "source": [
    "Nope! That doesn't work! We lost our \"h\"! **We have not *truth* but *trut*, and this is entirely unsatisfying!**\n",
    "\n",
    "Let me try to explain, and David and/or Mary can offer their thoughts. \n",
    "\n",
    "Yes, `text[12]` produces the terminal \"t\" of \"truth\" — but that \"t\" is not the twelfth character in the string; it is the **thirteenth**, since Python starts counting at 0. So at least we can sensibly interpret the command `text[0:13]` as meaning \"Show me every character from the start up to the thirteenth.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593d998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[0:13]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f1b247",
   "metadata": {},
   "source": [
    "Note that we can also write this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1222186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[:13]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5096bcd",
   "metadata": {},
   "source": [
    "And while we're at it, we may as well try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da46c62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[13:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f120410",
   "metadata": {},
   "source": [
    "What further insights does this provide us into the way that Python indexes (or indices, I suppose) work? \n",
    "\n",
    "`text[:13]` tells Python, \"show me everything from the start of the string all the way up to, **but not including**, `text[13]`\n",
    "\n",
    "`text[13:]` tells Python, \"show me everything from `text[13]` -- **including `text[13]` itself** -- all the way to the end.\"\n",
    "\n",
    "Okay, let's collectively make some random guesses until we get those famous first six words..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edfe7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35def68",
   "metadata": {},
   "source": [
    "Now let's play around a little bit more with the other parts of the `string[start:stop:step]` syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58410c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[0:13:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008b9af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[:13:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e790ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860ef43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d768c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fac836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911e6fe3",
   "metadata": {},
   "source": [
    "# 3b: String methods\n",
    "\n",
    "Let's now meet **methods**, which are a *special kind of function* that only belong to certain **data types** and which are written out differently than functions.\n",
    "\n",
    "As you'll recall, the syntax of a function is `function(argument)`, which we said was analogous to `verb(noun)`: functions are verb-y in that they **perform actions** on noun-like arguments.\n",
    "\n",
    "But not all kinds of actions are applicable or appropriate to all kind of nouns, as you will perhaps have discovered in your madlibs exercises last week (Can you really be \"eaten alive\" by an \"uproarious smoke\"?).\n",
    "\n",
    "**And not all functions are appropriate to all kinds of Python data types**.\n",
    "\n",
    "It makes sense to `print()` anything or check the `type()` of anything — but whereas it certainly makes sense to **convert a `str` to all lowercase letters**, it makes absolutely none to convert an `int` or a `float` or a `bool` to lowercase letters, since they are not composed of letters.\n",
    "\n",
    "This is not a hypothetical example: Python has a built-in way to turn strings into lowercase letters. But because it is something that only makes sense for one data type (`str`s), it is a **method** rather than a **function**.\n",
    "\n",
    "The syntax for methods is as follows: \n",
    "\n",
    "> `data.method(argument)`\n",
    "\n",
    "As you can see, they look quite a bit like functions, but they come **after** the data that you want to perform some action on, and they are \"attached\" to that data, as it were, by a period (`.`). \n",
    "\n",
    "Think of methods like **suffixes** — or, if you speak an inflected language like French or Polish, like grammatical words endings like the bolded bits in \"Tu aim**es**\" vs. \"Nous aim**ons**.\"\n",
    "\n",
    "Python has lots of cool string-specific methods. Let's explore a few:\n",
    "* `.lower()`: make lowercase\n",
    "* `.upper()`: make uppercase\n",
    "* `.title()`: make title case\n",
    "* `.replace()`: replace some text with other text (like \"Find and Replace\" in Word)\n",
    "* `.split()`: break a string into separate units, such as words\n",
    "\n",
    "Let's try out the make-it-lower case method, `.lower()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe5a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"AAAAAAAAAAAAAAAAAAAAAH\".lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c716ec8",
   "metadata": {},
   "source": [
    "A powerful method! A scream becomes a sigh!!\n",
    "\n",
    "Note that `.lower()` **does not require an argument**, which is also true of `.upper()` and `.title()`. \n",
    "\n",
    "Again, verbs provide a nice analogy. \n",
    "* Some verbs in certain contexts **require *objects***, like \"I am going to take... ***all of your oatmeal***\". \n",
    "* Some verbs in certain contexts **do not require objects**, like \"Oatmeal sucks.\"\n",
    "\n",
    "Some functions and methods require arguments, and some do not.\n",
    "* \"Lowercase this string, Python Interpreter!\" / \"Aaaaaaaaaaaaaaaah. Sure thing, boss!\"\n",
    "* \"Replace this string, Python Interpreter!\" / \"AAAAAAAAAAAAAAAAAAAAAAAAH! What do you want me to replace?? And with what?????\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a828b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b062ab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf7e031",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af67075",
   "metadata": {},
   "source": [
    "Note that running the above three commands ^^ doesn't actually alter the contents of the `text` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88320ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a972f83a",
   "metadata": {},
   "source": [
    "If we **wanted** to replace the value of `text` with a fully lowercased version of itself, how would we do it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90276786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed60bcb",
   "metadata": {},
   "source": [
    "Below is a look at the `.replace()` method, which as you can see takes **two arguments**, the text to replace with something else, and the \"something else\" to replace it with.\n",
    "\n",
    "`string.replace(\"text to remove\", \"text to insert in its place\")`\n",
    "\n",
    "Note that the **two arguments** are separated by commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea63d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Now approaching Ossington... Ossington Station\".replace(\"Ossington\", \"Christie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26701c31",
   "metadata": {},
   "source": [
    "You can use `names_of_string_variables` rather than `\"directly inputted text\"` at any position here. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d1ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_foucault = \"truth universally acknowledged\"\n",
    "post_foucault = \"spurious bias held in certain highly localized socio-political configurations\"\n",
    "\n",
    "text.replace(pre_foucault, post_foucault)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680ca907",
   "metadata": {},
   "source": [
    "As exciting as the above undoubtedly is, perhaps the most exciting string method for the purposes of our TTR experiments is \n",
    "\n",
    "> `.split()`\n",
    "\n",
    "— which takes a string and breaks it up into chunks.\n",
    "\n",
    "`.split()` doesn't **require** an argument. What does it do below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645161c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"April is the cruelest month, breeding / Lilacs out of the dead land\".split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb5fe67",
   "metadata": {},
   "source": [
    "The default, argument-less version of `split()` **\"splits on whitespace.\"** That is to say, any time it encounters any number of consecutive characters that Python (or the people who made Python) interpret as \"empty,\" it sharpens its fangs cuts them out. \n",
    "\n",
    "Whitespace characters include:\n",
    "* \"` `\": spaces (yes, spaces are characters!)\n",
    "* \"`\\t`\": tabs (yes, tabs are characters, and are represented as `\\t`)\n",
    "* \"`\\n`\": newlines or \"Return\"s (yes, \"Return\" or \"Enter\" is a character, and is represented as `\\n` — among other ways!)\n",
    "\n",
    "But `.split()` will **accept** an argument, if we want to split a string up by something other than whitespace.\n",
    "\n",
    "For instance, we could split Eliot up by \"`/`\" to divide this poem into lines..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b455d92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "waste_land = \"April is the cruelest month, breeding / Lilacs out of the dead land\"\n",
    "\n",
    "waste_land.split(\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ef3818",
   "metadata": {},
   "source": [
    "What happens to our splitting character, `/`, in the above command? Where does it go?\n",
    "\n",
    "And where does the output of the command go? Is it stored anywhere? How could we store it?\n",
    "\n",
    "Let's now split up our beloved `text` variable, from *Pride and Prejudice*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cbf32e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60a1740",
   "metadata": {},
   "source": [
    "But I'm interested in that output — I want to catch it in my butterfly net! Let's grab it and stick it in a variable called `text_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e11590",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_words = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89f5d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ba11bc",
   "metadata": {},
   "source": [
    "What a fascinating output! All those words, surrounded by quotation marks `'`, separated by commas `,`, and wrapped up in square brackets `[ ]`. **What on earth *is* this output?** Is it a **data type** we already know — *or is it perhaps something entirely new??*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afedb09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(text_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee97f1eb",
   "metadata": {},
   "source": [
    "# 3c: Lists!\n",
    "\n",
    "Is it weird to have a favourite data type? Maybe it is, maybe it isn't, but I/AH have one, and it's lists.\n",
    "\n",
    "Lists respond to the dreadful situation we described last class: *What if you want to put more than one thing in an envelope*? Lists are the data type that allows you put as many things as you want in an envelope. Those individual \"things\" can be any of the data types we've met this far, `str`s, `int`s, `float`s, `bool`s — whatever! In that way, they are sort of like a \"meta data-type,\" in that they store or contain lots of other sub-data-types.\n",
    "\n",
    "\n",
    "The best real-world equivalent I can think of for a list is... a list. \n",
    "\n",
    "Lists have names, and they contain multiple items.\n",
    "\n",
    "> **Grocery List**:\n",
    "> * Chocolate bar\n",
    "> * Chips\n",
    "> * Chocolate milk\n",
    "> * Another bag of chips\n",
    "\n",
    "The Python syntax for creating a new list variable is the following: `name = [item1, item2, item3, item4]`\n",
    "\n",
    "If I wanted to create a Python equivalent of the above list, I might do something like..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aa3040",
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_list = [\"Chocolate bar\", \"Chips\", \"Chocolate milk\", \"Another bag of chips\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601e47e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aac326",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grocery_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896f6811",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(grocery_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbc14d8",
   "metadata": {},
   "source": [
    "Let's try to take all the glorious values we created last week for our `LITERATURE`, `Woolf`, `wolf`, and `pi` viarables — and stick them into a new `list` variable called `bunch_o_stuff`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e39cb32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f22cb9da",
   "metadata": {},
   "source": [
    "## Indexing and Slicing Lists\n",
    "\n",
    "Good news! Both work exactly the same as for strings. Except that strings break down into characters, whereas lists break down into items or **elements**.\n",
    "\n",
    "If you want to pull out an individual item or **element** from a list, you can **index** it just like a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5408f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042e835b",
   "metadata": {},
   "source": [
    "What do you think will happen when we do the below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f242014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(grocery_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2775f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_list[0] + grocery_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f51442",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Boy I sure am hungry for some {grocery_list[2]} and some {grocery_list[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b737215",
   "metadata": {},
   "source": [
    "You can also **slice** `list`s in the same ways as you can `str`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c800ec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56b2d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(grocery_list[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e52600",
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_list[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a403fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_list[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffddb181",
   "metadata": {},
   "source": [
    "The `grocery_list` is cool and all, but I'm more interested in that list we creater earlier, `text_words`. Let's have another look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491e5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abee4ca",
   "metadata": {},
   "source": [
    "## `len()`\n",
    "\n",
    "Believe it or not, we're one mere tiny function away from being able to do something really exciting and absolutely essential to our TTR experiment: **count the number of tokens in a text**. \n",
    "\n",
    "**`.split()`**, you see, already got us to our first goal: it **\"tokenized\"** the text, i.e., **split it into individual words**. It didn't do a perfect job, of course, but it did pretty well. \n",
    "* What problems do you see with its tokenization?\n",
    "* Did it count the same number of words as you did?\n",
    "\n",
    "All we need now is a way to actually count the number of words in our list... which, blessedly, Python provides us in the form of a function called **`len()`**.\n",
    "\n",
    "**`len()`** — don't called him `leonard()` or `lenny()`, just `len()` — calculates the length of a variety of data types. For instance, let's try him out on a string, then a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7c969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ba6cb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(text_words)\n",
    "len(text_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ab8e20",
   "metadata": {},
   "source": [
    "Sadly, `len()` doesn't know what it means to count the length an `int`, a `float`, or a `bool`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2867cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(232)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d76f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(3.14159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4d3e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc1d8d5",
   "metadata": {},
   "source": [
    "When `len()` meets a `list`, he doesn't count anything within the actual items in the list; he only counts the number of elements or items in the list. We could, of course, ask him to count how long an individual element is, too, if it's the sort of thing that can be counted..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c195e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_words[4])\n",
    "len(text_words[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb78786",
   "metadata": {},
   "source": [
    "## The `.join()` method\n",
    "\n",
    "Before we move on to counting the actual number of words in an actual novel (!!!!), there's one more string method to introduce, now that we know about `list`s: the `.join()` method.\n",
    "\n",
    "It is used, perhaps unsurprisingly, to **join things together** — more specifically, to join together the items of a list into single string. The syntax is as follows:\n",
    "\n",
    "`string.join(list)` — where the `string` is whatever to want to mash **between** the items being joined and `list` is the list that you want to collapse into a single string.\n",
    "\n",
    "I've always found the syntax of this one pretty odd, but it is what it is, and it's definitely a useful method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7ab647",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" Mississippi, \".join([\"One\", \"two\", \"three\", \"four\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6764ed69",
   "metadata": {},
   "source": [
    "Notice that the `string` is **only** stuck in **between** items, so that in my application I'm left with a weirdly hanging four.\n",
    "\n",
    "Totally optional, but maybe on your own time you can try to figure out how the below works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceadd811",
   "metadata": {},
   "outputs": [],
   "source": [
    "divider = \" Mississauga\"\n",
    "(divider + \", \").join([\"One\", \"two\", \"three\", \"four\"]) + divider + \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aa3550",
   "metadata": {},
   "source": [
    "Here's a more practical application of `.join()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4dcacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(text_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e1879c",
   "metadata": {},
   "source": [
    "... and here we bring *Pride and Prejudice* into the 21st century..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75af137",
   "metadata": {},
   "outputs": [],
   "source": [
    "\", like, \".join(text_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f52d4a",
   "metadata": {},
   "source": [
    "# 3e: Loading a real-life text file into Python... and tokenizing it!\n",
    "\n",
    "We now have pretty much all the tools we need to perform an important part of our TTR exercise:\n",
    "* We can **tokenize** a sting by `.split()`ting it into words (more or less) and producing lists of words (more or less)\n",
    "* And we can count how many words there are in those lists with `len()`\n",
    "\n",
    "What we haven't learned to do, however, is actually load a novel into Python.\n",
    "\n",
    "Well, believe it or not, for that we only need a single line of code. \n",
    "\n",
    "It starts with the `open()` function, which we will provide with two arguments:\n",
    "* The **path** to the file we want to open, entered as `str` (so with `\"\"`s around it). This tells Python *where* that file is, relative to the notebook you currently have open. For today's example, we've already placed some **plain text** files on your JupyterHub, and they're in the same folder as this notebook. So the path is pretty simple: the name of the file, in quotation marks.\n",
    "* The type of **character encoding** that that file uses, a topic which requires its own subject heading.\n",
    "\n",
    "## Character encoding\n",
    "\n",
    "It's important to specify what kind of \"character encoding\" you're using because... computers don't actually understand what text *is*: they are just sign-manipulators who do what they're told."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e368f2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = \"P\"\n",
    "d = \"o\"\n",
    "a = \"o\"\n",
    "m = \"p\"\n",
    "print(A+d+a+m)\n",
    "A+d+a+m == \"Poop\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12243459",
   "metadata": {},
   "source": [
    "Although it would be handy if there were only one way of encoding text — one master system of signifiers and signifieds — there are in fact many systems. Among these are\n",
    "* The OG system, \"[ASCII](https://en.wikipedia.org/wiki/ASCII)\" — first devised in the 1960s! — which has pretty limited support for anything beyond English characters A-Z, a-z, 0-9, with some punctuation and special characters allowed. \n",
    "* The main encoding system we'll be using, \"[UTF-8](https://en.wikipedia.org/wiki/UTF-8)\" (derived from [Unicode](https://en.wikipedia.org/wiki/Unicode)), which is a lot better, but still — as Aditya Mukerjee points out in his essay “I Can Text You A Pile of Poo, But I Can’t Write My Name,” assigned this week — lacks characters that are essential to the Bengali alphabet as well as to many other non-English languages, when it has plenty of space to include these characters.\n",
    "\n",
    "Let's load a file that we've put in all of your JupyterHubs. It's called `\"sample_character_encoding.txt\"` and it is encoded in the UTF-8 standard.\n",
    "\n",
    "In the below command, we'll use the `open()` function to open the file, and then immediately apply the `.read()` method to that file. This is because the `open()` function produces a \"file object\" which only becomes what we want it to be — a `str` — once we apply this method to it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e120ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = open(\"sample_character_encoding.txt\", encoding=\"utf-8\").read()\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2887a478",
   "metadata": {},
   "source": [
    "If we try to open this same exact file with a different encoding system called ISO-8859-1, we get a bit of a mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bcf5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = open(\"sample_character_encoding.txt\", encoding=\"iso-8859-1\").read()\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbedcba",
   "metadata": {},
   "source": [
    "If we try to open this same exact file using Ye Olde Fashionede ASCII encoding, we just get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985da885",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = open(\"sample_character_encoding.txt\", encoding=\"ascii\").read()\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c841f4",
   "metadata": {},
   "source": [
    "Now let's try something loading something a bit longer, something we've actually all read... ***The Sign of the Four***! \n",
    "\n",
    "We've already conveniently put a copy of it — `sign-of-four.txt`, sourced from Project Gutenberg and encoded in UTF-8 — in your JupyterHubs, in the same folder as where this notebook lives. Let's load it into a variable called `sot4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10768b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sot4 = open(\"sign-of-four.txt\", encoding=\"utf-8\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185d709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sot4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6544ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sot4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d48b4a",
   "metadata": {},
   "source": [
    "Let's have a look inside!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0df422",
   "metadata": {},
   "outputs": [],
   "source": [
    "sot4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987ded05",
   "metadata": {},
   "source": [
    "Talk about **Literature and Data**! Here is our precious **literature** being **treated as data**.\n",
    "* How does it make you feel?\n",
    "* How does looking at the text in this way compare to looking at it in the pages of a book?\n",
    "\n",
    "\n",
    "\n",
    "Now, you might be wondering what all those `\\n` things are. It was briefly mentioned above — but in case you've forgotten, have a look at the [original text file on Project Gutenberg](https://www.gutenberg.org/cache/epub/2097/pg2097.txt). Does that provide any clues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f479518",
   "metadata": {},
   "outputs": [],
   "source": [
    "sot4[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17c7ba9",
   "metadata": {},
   "source": [
    "Notice that if we `print()` this out, we get quite different output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d29f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sot4[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9f329f",
   "metadata": {},
   "source": [
    "Anyway, let's try **tokenizing** this as is and look at the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad82e025",
   "metadata": {},
   "outputs": [],
   "source": [
    "sot4_words = sot4.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211b81b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sot4_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a23012",
   "metadata": {},
   "source": [
    "And then... just one more step to get our number of tokens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be65e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sot4_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a341f105",
   "metadata": {},
   "source": [
    "Now, this notably **does not** agree with the number I had on the slides last week, which was **43,520**. What do you think could explain the difference?\n",
    "\n",
    "By the way, how could we calculate how different the two token counts we got are, as a percentage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad798b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d057d5f7",
   "metadata": {},
   "source": [
    "In terms of the TTR project, we now know how to:\n",
    "* load a file\n",
    "* split it into words\n",
    "* count the number of words\n",
    "\n",
    "We don't have the tools yet to:\n",
    "* remove punctuation \n",
    "* automatically go into a folder full of lots and lots of files, load them all up, and count their lengths\n",
    "* count unique types\n",
    "* automatically standardize our sample size\n",
    "\n",
    "To do all the above, we'll need to learn a bit about iteration and loops. Which we'll do next class..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b3e835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
